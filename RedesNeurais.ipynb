{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNivW3UWYXKtkGCZyC13Stw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Szaboltz/data_science_ads/blob/master/RedesNeurais.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "WKEnk_waHpPO"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from yellowbrick.classifier import ConfusionMatrix\n",
        "from sklearn.neural_network import MLPClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d3AbqUHIA8T",
        "outputId": "b25ad367-1efa-4991-bb9f-01786afa5970"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "caminho = '/content/drive/MyDrive/ADS/DataScience/Source/'"
      ],
      "metadata": {
        "id": "vqKWoiM7IXwG"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(caminho + 'credit.pkl', 'rb') as f:\n",
        "  X_credit_treinamento, y_credit_treinamento, X_credit_teste, y_credit_teste = pickle.load(f)"
      ],
      "metadata": {
        "id": "ebq6NBAtIYfV"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rede_neural_credit = MLPClassifier(verbose = True,\n",
        "                                   max_iter = 1500,\n",
        "                                   tol=0.0000100,\n",
        "                                   solver='adam',\n",
        "                                   activation='relu',\n",
        "                                   hidden_layer_sizes=(10, 10))\n",
        "\n",
        "rede_neural_credit.fit(X_credit_treinamento, y_credit_treinamento)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sAGr6fKiY8ny",
        "outputId": "4e9b9e0c-98a0-4e52-cd0f-fe824f29825e"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 0.75868978\n",
            "Iteration 2, loss = 0.71582681\n",
            "Iteration 3, loss = 0.67760331\n",
            "Iteration 4, loss = 0.64321146\n",
            "Iteration 5, loss = 0.61237486\n",
            "Iteration 6, loss = 0.58520455\n",
            "Iteration 7, loss = 0.55997910\n",
            "Iteration 8, loss = 0.53759047\n",
            "Iteration 9, loss = 0.51704577\n",
            "Iteration 10, loss = 0.49792341\n",
            "Iteration 11, loss = 0.48027377\n",
            "Iteration 12, loss = 0.46319059\n",
            "Iteration 13, loss = 0.44703562\n",
            "Iteration 14, loss = 0.43120982\n",
            "Iteration 15, loss = 0.41635295\n",
            "Iteration 16, loss = 0.40195449\n",
            "Iteration 17, loss = 0.38811615\n",
            "Iteration 18, loss = 0.37492474\n",
            "Iteration 19, loss = 0.36205000\n",
            "Iteration 20, loss = 0.34936529\n",
            "Iteration 21, loss = 0.33701412\n",
            "Iteration 22, loss = 0.32476489\n",
            "Iteration 23, loss = 0.31264980\n",
            "Iteration 24, loss = 0.30074990\n",
            "Iteration 25, loss = 0.28896935\n",
            "Iteration 26, loss = 0.27755152\n",
            "Iteration 27, loss = 0.26659933\n",
            "Iteration 28, loss = 0.25581560\n",
            "Iteration 29, loss = 0.24553156\n",
            "Iteration 30, loss = 0.23576959\n",
            "Iteration 31, loss = 0.22653307\n",
            "Iteration 32, loss = 0.21768919\n",
            "Iteration 33, loss = 0.20935384\n",
            "Iteration 34, loss = 0.20140081\n",
            "Iteration 35, loss = 0.19404120\n",
            "Iteration 36, loss = 0.18706269\n",
            "Iteration 37, loss = 0.18056884\n",
            "Iteration 38, loss = 0.17465530\n",
            "Iteration 39, loss = 0.16907448\n",
            "Iteration 40, loss = 0.16378296\n",
            "Iteration 41, loss = 0.15895078\n",
            "Iteration 42, loss = 0.15452223\n",
            "Iteration 43, loss = 0.15024569\n",
            "Iteration 44, loss = 0.14642884\n",
            "Iteration 45, loss = 0.14276461\n",
            "Iteration 46, loss = 0.13937185\n",
            "Iteration 47, loss = 0.13620876\n",
            "Iteration 48, loss = 0.13325017\n",
            "Iteration 49, loss = 0.13040826\n",
            "Iteration 50, loss = 0.12782611\n",
            "Iteration 51, loss = 0.12529344\n",
            "Iteration 52, loss = 0.12292640\n",
            "Iteration 53, loss = 0.12078644\n",
            "Iteration 54, loss = 0.11859425\n",
            "Iteration 55, loss = 0.11656396\n",
            "Iteration 56, loss = 0.11452184\n",
            "Iteration 57, loss = 0.11259805\n",
            "Iteration 58, loss = 0.11078996\n",
            "Iteration 59, loss = 0.10899841\n",
            "Iteration 60, loss = 0.10744290\n",
            "Iteration 61, loss = 0.10573820\n",
            "Iteration 62, loss = 0.10431058\n",
            "Iteration 63, loss = 0.10272672\n",
            "Iteration 64, loss = 0.10123590\n",
            "Iteration 65, loss = 0.09984816\n",
            "Iteration 66, loss = 0.09853700\n",
            "Iteration 67, loss = 0.09719555\n",
            "Iteration 68, loss = 0.09592382\n",
            "Iteration 69, loss = 0.09469718\n",
            "Iteration 70, loss = 0.09337403\n",
            "Iteration 71, loss = 0.09221401\n",
            "Iteration 72, loss = 0.09109162\n",
            "Iteration 73, loss = 0.08999642\n",
            "Iteration 74, loss = 0.08897627\n",
            "Iteration 75, loss = 0.08792168\n",
            "Iteration 76, loss = 0.08693629\n",
            "Iteration 77, loss = 0.08601101\n",
            "Iteration 78, loss = 0.08504420\n",
            "Iteration 79, loss = 0.08413276\n",
            "Iteration 80, loss = 0.08325359\n",
            "Iteration 81, loss = 0.08238437\n",
            "Iteration 82, loss = 0.08147712\n",
            "Iteration 83, loss = 0.08058119\n",
            "Iteration 84, loss = 0.07977140\n",
            "Iteration 85, loss = 0.07893866\n",
            "Iteration 86, loss = 0.07809443\n",
            "Iteration 87, loss = 0.07731649\n",
            "Iteration 88, loss = 0.07658795\n",
            "Iteration 89, loss = 0.07582418\n",
            "Iteration 90, loss = 0.07509571\n",
            "Iteration 91, loss = 0.07435854\n",
            "Iteration 92, loss = 0.07361483\n",
            "Iteration 93, loss = 0.07287748\n",
            "Iteration 94, loss = 0.07217852\n",
            "Iteration 95, loss = 0.07144571\n",
            "Iteration 96, loss = 0.07075495\n",
            "Iteration 97, loss = 0.07009355\n",
            "Iteration 98, loss = 0.06941207\n",
            "Iteration 99, loss = 0.06869856\n",
            "Iteration 100, loss = 0.06804515\n",
            "Iteration 101, loss = 0.06737265\n",
            "Iteration 102, loss = 0.06670395\n",
            "Iteration 103, loss = 0.06608176\n",
            "Iteration 104, loss = 0.06538756\n",
            "Iteration 105, loss = 0.06486255\n",
            "Iteration 106, loss = 0.06417882\n",
            "Iteration 107, loss = 0.06356481\n",
            "Iteration 108, loss = 0.06291736\n",
            "Iteration 109, loss = 0.06232478\n",
            "Iteration 110, loss = 0.06174246\n",
            "Iteration 111, loss = 0.06116083\n",
            "Iteration 112, loss = 0.06056930\n",
            "Iteration 113, loss = 0.05996915\n",
            "Iteration 114, loss = 0.05936549\n",
            "Iteration 115, loss = 0.05883450\n",
            "Iteration 116, loss = 0.05814644\n",
            "Iteration 117, loss = 0.05761287\n",
            "Iteration 118, loss = 0.05711839\n",
            "Iteration 119, loss = 0.05653950\n",
            "Iteration 120, loss = 0.05590827\n",
            "Iteration 121, loss = 0.05535117\n",
            "Iteration 122, loss = 0.05482653\n",
            "Iteration 123, loss = 0.05432025\n",
            "Iteration 124, loss = 0.05379223\n",
            "Iteration 125, loss = 0.05326225\n",
            "Iteration 126, loss = 0.05277802\n",
            "Iteration 127, loss = 0.05225659\n",
            "Iteration 128, loss = 0.05170458\n",
            "Iteration 129, loss = 0.05120472\n",
            "Iteration 130, loss = 0.05065088\n",
            "Iteration 131, loss = 0.05015983\n",
            "Iteration 132, loss = 0.04981064\n",
            "Iteration 133, loss = 0.04927859\n",
            "Iteration 134, loss = 0.04882797\n",
            "Iteration 135, loss = 0.04827151\n",
            "Iteration 136, loss = 0.04794836\n",
            "Iteration 137, loss = 0.04749222\n",
            "Iteration 138, loss = 0.04699516\n",
            "Iteration 139, loss = 0.04658566\n",
            "Iteration 140, loss = 0.04615124\n",
            "Iteration 141, loss = 0.04576205\n",
            "Iteration 142, loss = 0.04529137\n",
            "Iteration 143, loss = 0.04494194\n",
            "Iteration 144, loss = 0.04453513\n",
            "Iteration 145, loss = 0.04419083\n",
            "Iteration 146, loss = 0.04376825\n",
            "Iteration 147, loss = 0.04341572\n",
            "Iteration 148, loss = 0.04306204\n",
            "Iteration 149, loss = 0.04262718\n",
            "Iteration 150, loss = 0.04229434\n",
            "Iteration 151, loss = 0.04186856\n",
            "Iteration 152, loss = 0.04156970\n",
            "Iteration 153, loss = 0.04126952\n",
            "Iteration 154, loss = 0.04086711\n",
            "Iteration 155, loss = 0.04055666\n",
            "Iteration 156, loss = 0.04018915\n",
            "Iteration 157, loss = 0.03993361\n",
            "Iteration 158, loss = 0.03954397\n",
            "Iteration 159, loss = 0.03929031\n",
            "Iteration 160, loss = 0.03898940\n",
            "Iteration 161, loss = 0.03865409\n",
            "Iteration 162, loss = 0.03837996\n",
            "Iteration 163, loss = 0.03815132\n",
            "Iteration 164, loss = 0.03774577\n",
            "Iteration 165, loss = 0.03747128\n",
            "Iteration 166, loss = 0.03723692\n",
            "Iteration 167, loss = 0.03692243\n",
            "Iteration 168, loss = 0.03663829\n",
            "Iteration 169, loss = 0.03639017\n",
            "Iteration 170, loss = 0.03610710\n",
            "Iteration 171, loss = 0.03581499\n",
            "Iteration 172, loss = 0.03555242\n",
            "Iteration 173, loss = 0.03547339\n",
            "Iteration 174, loss = 0.03507142\n",
            "Iteration 175, loss = 0.03479202\n",
            "Iteration 176, loss = 0.03453690\n",
            "Iteration 177, loss = 0.03427163\n",
            "Iteration 178, loss = 0.03408582\n",
            "Iteration 179, loss = 0.03382201\n",
            "Iteration 180, loss = 0.03353881\n",
            "Iteration 181, loss = 0.03333336\n",
            "Iteration 182, loss = 0.03316985\n",
            "Iteration 183, loss = 0.03285858\n",
            "Iteration 184, loss = 0.03265681\n",
            "Iteration 185, loss = 0.03246021\n",
            "Iteration 186, loss = 0.03221180\n",
            "Iteration 187, loss = 0.03201468\n",
            "Iteration 188, loss = 0.03180594\n",
            "Iteration 189, loss = 0.03169018\n",
            "Iteration 190, loss = 0.03151827\n",
            "Iteration 191, loss = 0.03120816\n",
            "Iteration 192, loss = 0.03100571\n",
            "Iteration 193, loss = 0.03094499\n",
            "Iteration 194, loss = 0.03065049\n",
            "Iteration 195, loss = 0.03041634\n",
            "Iteration 196, loss = 0.03022492\n",
            "Iteration 197, loss = 0.03002086\n",
            "Iteration 198, loss = 0.02983536\n",
            "Iteration 199, loss = 0.02968771\n",
            "Iteration 200, loss = 0.02948254\n",
            "Iteration 201, loss = 0.02929474\n",
            "Iteration 202, loss = 0.02914565\n",
            "Iteration 203, loss = 0.02895309\n",
            "Iteration 204, loss = 0.02877650\n",
            "Iteration 205, loss = 0.02861361\n",
            "Iteration 206, loss = 0.02852994\n",
            "Iteration 207, loss = 0.02823784\n",
            "Iteration 208, loss = 0.02813095\n",
            "Iteration 209, loss = 0.02790504\n",
            "Iteration 210, loss = 0.02775633\n",
            "Iteration 211, loss = 0.02756104\n",
            "Iteration 212, loss = 0.02738236\n",
            "Iteration 213, loss = 0.02723413\n",
            "Iteration 214, loss = 0.02702439\n",
            "Iteration 215, loss = 0.02692459\n",
            "Iteration 216, loss = 0.02677897\n",
            "Iteration 217, loss = 0.02656729\n",
            "Iteration 218, loss = 0.02640141\n",
            "Iteration 219, loss = 0.02623719\n",
            "Iteration 220, loss = 0.02611993\n",
            "Iteration 221, loss = 0.02595520\n",
            "Iteration 222, loss = 0.02588066\n",
            "Iteration 223, loss = 0.02560956\n",
            "Iteration 224, loss = 0.02547546\n",
            "Iteration 225, loss = 0.02541392\n",
            "Iteration 226, loss = 0.02531864\n",
            "Iteration 227, loss = 0.02507795\n",
            "Iteration 228, loss = 0.02490500\n",
            "Iteration 229, loss = 0.02471162\n",
            "Iteration 230, loss = 0.02452901\n",
            "Iteration 231, loss = 0.02439433\n",
            "Iteration 232, loss = 0.02428748\n",
            "Iteration 233, loss = 0.02411205\n",
            "Iteration 234, loss = 0.02400842\n",
            "Iteration 235, loss = 0.02384954\n",
            "Iteration 236, loss = 0.02372979\n",
            "Iteration 237, loss = 0.02356180\n",
            "Iteration 238, loss = 0.02352518\n",
            "Iteration 239, loss = 0.02333220\n",
            "Iteration 240, loss = 0.02319043\n",
            "Iteration 241, loss = 0.02311952\n",
            "Iteration 242, loss = 0.02291797\n",
            "Iteration 243, loss = 0.02284339\n",
            "Iteration 244, loss = 0.02268302\n",
            "Iteration 245, loss = 0.02254673\n",
            "Iteration 246, loss = 0.02241316\n",
            "Iteration 247, loss = 0.02234229\n",
            "Iteration 248, loss = 0.02229094\n",
            "Iteration 249, loss = 0.02207733\n",
            "Iteration 250, loss = 0.02197183\n",
            "Iteration 251, loss = 0.02188586\n",
            "Iteration 252, loss = 0.02174131\n",
            "Iteration 253, loss = 0.02163189\n",
            "Iteration 254, loss = 0.02148907\n",
            "Iteration 255, loss = 0.02140018\n",
            "Iteration 256, loss = 0.02132004\n",
            "Iteration 257, loss = 0.02112624\n",
            "Iteration 258, loss = 0.02109374\n",
            "Iteration 259, loss = 0.02098435\n",
            "Iteration 260, loss = 0.02093966\n",
            "Iteration 261, loss = 0.02076588\n",
            "Iteration 262, loss = 0.02061993\n",
            "Iteration 263, loss = 0.02055966\n",
            "Iteration 264, loss = 0.02042904\n",
            "Iteration 265, loss = 0.02030644\n",
            "Iteration 266, loss = 0.02028705\n",
            "Iteration 267, loss = 0.02011498\n",
            "Iteration 268, loss = 0.02000088\n",
            "Iteration 269, loss = 0.01995704\n",
            "Iteration 270, loss = 0.01982779\n",
            "Iteration 271, loss = 0.01977190\n",
            "Iteration 272, loss = 0.01964296\n",
            "Iteration 273, loss = 0.01956682\n",
            "Iteration 274, loss = 0.01950307\n",
            "Iteration 275, loss = 0.01939773\n",
            "Iteration 276, loss = 0.01932751\n",
            "Iteration 277, loss = 0.01919138\n",
            "Iteration 278, loss = 0.01914559\n",
            "Iteration 279, loss = 0.01902831\n",
            "Iteration 280, loss = 0.01891654\n",
            "Iteration 281, loss = 0.01885852\n",
            "Iteration 282, loss = 0.01879159\n",
            "Iteration 283, loss = 0.01875218\n",
            "Iteration 284, loss = 0.01860320\n",
            "Iteration 285, loss = 0.01848322\n",
            "Iteration 286, loss = 0.01841562\n",
            "Iteration 287, loss = 0.01834752\n",
            "Iteration 288, loss = 0.01828609\n",
            "Iteration 289, loss = 0.01815512\n",
            "Iteration 290, loss = 0.01811276\n",
            "Iteration 291, loss = 0.01813849\n",
            "Iteration 292, loss = 0.01798192\n",
            "Iteration 293, loss = 0.01786828\n",
            "Iteration 294, loss = 0.01782715\n",
            "Iteration 295, loss = 0.01777093\n",
            "Iteration 296, loss = 0.01769891\n",
            "Iteration 297, loss = 0.01757524\n",
            "Iteration 298, loss = 0.01749338\n",
            "Iteration 299, loss = 0.01745827\n",
            "Iteration 300, loss = 0.01738101\n",
            "Iteration 301, loss = 0.01723904\n",
            "Iteration 302, loss = 0.01720141\n",
            "Iteration 303, loss = 0.01712456\n",
            "Iteration 304, loss = 0.01700601\n",
            "Iteration 305, loss = 0.01696524\n",
            "Iteration 306, loss = 0.01690197\n",
            "Iteration 307, loss = 0.01682537\n",
            "Iteration 308, loss = 0.01673088\n",
            "Iteration 309, loss = 0.01667524\n",
            "Iteration 310, loss = 0.01668438\n",
            "Iteration 311, loss = 0.01654340\n",
            "Iteration 312, loss = 0.01653829\n",
            "Iteration 313, loss = 0.01654740\n",
            "Iteration 314, loss = 0.01634693\n",
            "Iteration 315, loss = 0.01627166\n",
            "Iteration 316, loss = 0.01621578\n",
            "Iteration 317, loss = 0.01613112\n",
            "Iteration 318, loss = 0.01605031\n",
            "Iteration 319, loss = 0.01601439\n",
            "Iteration 320, loss = 0.01594079\n",
            "Iteration 321, loss = 0.01585907\n",
            "Iteration 322, loss = 0.01578706\n",
            "Iteration 323, loss = 0.01576761\n",
            "Iteration 324, loss = 0.01564956\n",
            "Iteration 325, loss = 0.01558387\n",
            "Iteration 326, loss = 0.01557312\n",
            "Iteration 327, loss = 0.01544083\n",
            "Iteration 328, loss = 0.01537572\n",
            "Iteration 329, loss = 0.01531426\n",
            "Iteration 330, loss = 0.01526744\n",
            "Iteration 331, loss = 0.01522090\n",
            "Iteration 332, loss = 0.01513805\n",
            "Iteration 333, loss = 0.01507987\n",
            "Iteration 334, loss = 0.01497081\n",
            "Iteration 335, loss = 0.01496076\n",
            "Iteration 336, loss = 0.01488551\n",
            "Iteration 337, loss = 0.01484720\n",
            "Iteration 338, loss = 0.01474955\n",
            "Iteration 339, loss = 0.01473135\n",
            "Iteration 340, loss = 0.01466484\n",
            "Iteration 341, loss = 0.01464875\n",
            "Iteration 342, loss = 0.01452789\n",
            "Iteration 343, loss = 0.01447624\n",
            "Iteration 344, loss = 0.01441644\n",
            "Iteration 345, loss = 0.01436722\n",
            "Iteration 346, loss = 0.01432680\n",
            "Iteration 347, loss = 0.01427818\n",
            "Iteration 348, loss = 0.01420983\n",
            "Iteration 349, loss = 0.01413734\n",
            "Iteration 350, loss = 0.01408845\n",
            "Iteration 351, loss = 0.01406347\n",
            "Iteration 352, loss = 0.01397458\n",
            "Iteration 353, loss = 0.01393016\n",
            "Iteration 354, loss = 0.01388293\n",
            "Iteration 355, loss = 0.01384551\n",
            "Iteration 356, loss = 0.01377984\n",
            "Iteration 357, loss = 0.01370691\n",
            "Iteration 358, loss = 0.01381864\n",
            "Iteration 359, loss = 0.01361989\n",
            "Iteration 360, loss = 0.01356870\n",
            "Iteration 361, loss = 0.01350576\n",
            "Iteration 362, loss = 0.01349492\n",
            "Iteration 363, loss = 0.01343948\n",
            "Iteration 364, loss = 0.01344432\n",
            "Iteration 365, loss = 0.01328567\n",
            "Iteration 366, loss = 0.01329979\n",
            "Iteration 367, loss = 0.01325501\n",
            "Iteration 368, loss = 0.01321620\n",
            "Iteration 369, loss = 0.01311660\n",
            "Iteration 370, loss = 0.01305592\n",
            "Iteration 371, loss = 0.01306742\n",
            "Iteration 372, loss = 0.01297626\n",
            "Iteration 373, loss = 0.01293293\n",
            "Iteration 374, loss = 0.01288051\n",
            "Iteration 375, loss = 0.01283539\n",
            "Iteration 376, loss = 0.01278648\n",
            "Iteration 377, loss = 0.01277460\n",
            "Iteration 378, loss = 0.01269608\n",
            "Iteration 379, loss = 0.01265739\n",
            "Iteration 380, loss = 0.01260276\n",
            "Iteration 381, loss = 0.01266284\n",
            "Iteration 382, loss = 0.01271282\n",
            "Iteration 383, loss = 0.01239651\n",
            "Iteration 384, loss = 0.01242298\n",
            "Iteration 385, loss = 0.01254440\n",
            "Iteration 386, loss = 0.01237119\n",
            "Iteration 387, loss = 0.01230617\n",
            "Iteration 388, loss = 0.01227621\n",
            "Iteration 389, loss = 0.01220605\n",
            "Iteration 390, loss = 0.01215054\n",
            "Iteration 391, loss = 0.01212961\n",
            "Iteration 392, loss = 0.01206739\n",
            "Iteration 393, loss = 0.01205146\n",
            "Iteration 394, loss = 0.01199160\n",
            "Iteration 395, loss = 0.01196211\n",
            "Iteration 396, loss = 0.01191944\n",
            "Iteration 397, loss = 0.01182120\n",
            "Iteration 398, loss = 0.01175986\n",
            "Iteration 399, loss = 0.01173727\n",
            "Iteration 400, loss = 0.01169813\n",
            "Iteration 401, loss = 0.01165783\n",
            "Iteration 402, loss = 0.01167277\n",
            "Iteration 403, loss = 0.01156966\n",
            "Iteration 404, loss = 0.01151278\n",
            "Iteration 405, loss = 0.01159478\n",
            "Iteration 406, loss = 0.01147317\n",
            "Iteration 407, loss = 0.01138325\n",
            "Iteration 408, loss = 0.01140535\n",
            "Iteration 409, loss = 0.01134259\n",
            "Iteration 410, loss = 0.01130357\n",
            "Iteration 411, loss = 0.01126488\n",
            "Iteration 412, loss = 0.01126138\n",
            "Iteration 413, loss = 0.01116034\n",
            "Iteration 414, loss = 0.01111572\n",
            "Iteration 415, loss = 0.01110032\n",
            "Iteration 416, loss = 0.01118031\n",
            "Iteration 417, loss = 0.01100318\n",
            "Iteration 418, loss = 0.01100254\n",
            "Iteration 419, loss = 0.01097586\n",
            "Iteration 420, loss = 0.01090010\n",
            "Iteration 421, loss = 0.01087137\n",
            "Iteration 422, loss = 0.01079150\n",
            "Iteration 423, loss = 0.01081343\n",
            "Iteration 424, loss = 0.01075055\n",
            "Iteration 425, loss = 0.01069698\n",
            "Iteration 426, loss = 0.01062243\n",
            "Iteration 427, loss = 0.01064333\n",
            "Iteration 428, loss = 0.01061511\n",
            "Iteration 429, loss = 0.01048246\n",
            "Iteration 430, loss = 0.01043649\n",
            "Iteration 431, loss = 0.01037413\n",
            "Iteration 432, loss = 0.01039559\n",
            "Iteration 433, loss = 0.01030517\n",
            "Iteration 434, loss = 0.01024328\n",
            "Iteration 435, loss = 0.01023284\n",
            "Iteration 436, loss = 0.01017938\n",
            "Iteration 437, loss = 0.01013398\n",
            "Iteration 438, loss = 0.01008347\n",
            "Iteration 439, loss = 0.01005732\n",
            "Iteration 440, loss = 0.01003507\n",
            "Iteration 441, loss = 0.01006570\n",
            "Iteration 442, loss = 0.01002633\n",
            "Iteration 443, loss = 0.00999058\n",
            "Iteration 444, loss = 0.00997429\n",
            "Iteration 445, loss = 0.00980614\n",
            "Iteration 446, loss = 0.00993128\n",
            "Iteration 447, loss = 0.00985275\n",
            "Iteration 448, loss = 0.00989035\n",
            "Iteration 449, loss = 0.00967644\n",
            "Iteration 450, loss = 0.00964041\n",
            "Iteration 451, loss = 0.00960832\n",
            "Iteration 452, loss = 0.00957899\n",
            "Iteration 453, loss = 0.00960624\n",
            "Iteration 454, loss = 0.00948983\n",
            "Iteration 455, loss = 0.00950017\n",
            "Iteration 456, loss = 0.00942255\n",
            "Iteration 457, loss = 0.00935953\n",
            "Iteration 458, loss = 0.00934480\n",
            "Iteration 459, loss = 0.00931029\n",
            "Iteration 460, loss = 0.00925671\n",
            "Iteration 461, loss = 0.00925499\n",
            "Iteration 462, loss = 0.00923879\n",
            "Iteration 463, loss = 0.00918415\n",
            "Iteration 464, loss = 0.00914501\n",
            "Iteration 465, loss = 0.00912522\n",
            "Iteration 466, loss = 0.00906976\n",
            "Iteration 467, loss = 0.00905033\n",
            "Iteration 468, loss = 0.00900297\n",
            "Iteration 469, loss = 0.00900120\n",
            "Iteration 470, loss = 0.00898045\n",
            "Iteration 471, loss = 0.00895352\n",
            "Iteration 472, loss = 0.00892103\n",
            "Iteration 473, loss = 0.00882171\n",
            "Iteration 474, loss = 0.00882939\n",
            "Iteration 475, loss = 0.00878282\n",
            "Iteration 476, loss = 0.00872524\n",
            "Iteration 477, loss = 0.00868688\n",
            "Iteration 478, loss = 0.00870084\n",
            "Iteration 479, loss = 0.00865685\n",
            "Iteration 480, loss = 0.00862834\n",
            "Iteration 481, loss = 0.00869014\n",
            "Iteration 482, loss = 0.00856150\n",
            "Iteration 483, loss = 0.00856129\n",
            "Iteration 484, loss = 0.00849446\n",
            "Iteration 485, loss = 0.00854545\n",
            "Iteration 486, loss = 0.00845358\n",
            "Iteration 487, loss = 0.00841211\n",
            "Iteration 488, loss = 0.00841341\n",
            "Iteration 489, loss = 0.00832521\n",
            "Iteration 490, loss = 0.00838060\n",
            "Iteration 491, loss = 0.00833257\n",
            "Iteration 492, loss = 0.00833755\n",
            "Iteration 493, loss = 0.00845858\n",
            "Iteration 494, loss = 0.00815706\n",
            "Iteration 495, loss = 0.00827277\n",
            "Iteration 496, loss = 0.00828046\n",
            "Iteration 497, loss = 0.00815473\n",
            "Iteration 498, loss = 0.00813290\n",
            "Iteration 499, loss = 0.00807215\n",
            "Iteration 500, loss = 0.00810413\n",
            "Iteration 501, loss = 0.00806754\n",
            "Iteration 502, loss = 0.00803608\n",
            "Iteration 503, loss = 0.00798883\n",
            "Iteration 504, loss = 0.00796239\n",
            "Iteration 505, loss = 0.00789622\n",
            "Iteration 506, loss = 0.00795000\n",
            "Iteration 507, loss = 0.00788699\n",
            "Iteration 508, loss = 0.00790877\n",
            "Iteration 509, loss = 0.00786543\n",
            "Iteration 510, loss = 0.00776997\n",
            "Iteration 511, loss = 0.00777733\n",
            "Iteration 512, loss = 0.00777980\n",
            "Iteration 513, loss = 0.00772303\n",
            "Iteration 514, loss = 0.00773202\n",
            "Iteration 515, loss = 0.00768630\n",
            "Iteration 516, loss = 0.00772443\n",
            "Iteration 517, loss = 0.00770165\n",
            "Iteration 518, loss = 0.00760327\n",
            "Iteration 519, loss = 0.00760649\n",
            "Iteration 520, loss = 0.00757529\n",
            "Iteration 521, loss = 0.00752425\n",
            "Iteration 522, loss = 0.00745887\n",
            "Iteration 523, loss = 0.00745368\n",
            "Iteration 524, loss = 0.00748184\n",
            "Iteration 525, loss = 0.00738475\n",
            "Iteration 526, loss = 0.00736697\n",
            "Iteration 527, loss = 0.00737463\n",
            "Iteration 528, loss = 0.00746412\n",
            "Iteration 529, loss = 0.00736510\n",
            "Iteration 530, loss = 0.00728902\n",
            "Iteration 531, loss = 0.00736731\n",
            "Iteration 532, loss = 0.00732756\n",
            "Iteration 533, loss = 0.00725456\n",
            "Iteration 534, loss = 0.00718955\n",
            "Iteration 535, loss = 0.00726745\n",
            "Iteration 536, loss = 0.00722770\n",
            "Iteration 537, loss = 0.00716140\n",
            "Iteration 538, loss = 0.00710836\n",
            "Iteration 539, loss = 0.00710162\n",
            "Iteration 540, loss = 0.00706194\n",
            "Iteration 541, loss = 0.00708115\n",
            "Iteration 542, loss = 0.00706860\n",
            "Iteration 543, loss = 0.00703529\n",
            "Iteration 544, loss = 0.00702606\n",
            "Iteration 545, loss = 0.00700070\n",
            "Iteration 546, loss = 0.00696731\n",
            "Iteration 547, loss = 0.00696113\n",
            "Iteration 548, loss = 0.00691834\n",
            "Iteration 549, loss = 0.00691824\n",
            "Iteration 550, loss = 0.00689226\n",
            "Iteration 551, loss = 0.00697179\n",
            "Iteration 552, loss = 0.00681535\n",
            "Iteration 553, loss = 0.00690147\n",
            "Iteration 554, loss = 0.00682453\n",
            "Iteration 555, loss = 0.00683696\n",
            "Iteration 556, loss = 0.00679636\n",
            "Iteration 557, loss = 0.00670088\n",
            "Iteration 558, loss = 0.00676023\n",
            "Iteration 559, loss = 0.00670814\n",
            "Iteration 560, loss = 0.00667129\n",
            "Iteration 561, loss = 0.00669113\n",
            "Iteration 562, loss = 0.00664901\n",
            "Iteration 563, loss = 0.00663196\n",
            "Iteration 564, loss = 0.00655975\n",
            "Iteration 565, loss = 0.00656242\n",
            "Iteration 566, loss = 0.00654083\n",
            "Iteration 567, loss = 0.00659543\n",
            "Iteration 568, loss = 0.00648270\n",
            "Iteration 569, loss = 0.00654984\n",
            "Iteration 570, loss = 0.00652850\n",
            "Iteration 571, loss = 0.00644385\n",
            "Iteration 572, loss = 0.00643699\n",
            "Iteration 573, loss = 0.00641524\n",
            "Iteration 574, loss = 0.00649235\n",
            "Iteration 575, loss = 0.00639328\n",
            "Iteration 576, loss = 0.00637466\n",
            "Iteration 577, loss = 0.00632938\n",
            "Iteration 578, loss = 0.00639081\n",
            "Iteration 579, loss = 0.00628415\n",
            "Iteration 580, loss = 0.00631573\n",
            "Iteration 581, loss = 0.00632577\n",
            "Iteration 582, loss = 0.00623547\n",
            "Iteration 583, loss = 0.00623057\n",
            "Iteration 584, loss = 0.00620636\n",
            "Iteration 585, loss = 0.00618057\n",
            "Iteration 586, loss = 0.00616214\n",
            "Iteration 587, loss = 0.00623780\n",
            "Iteration 588, loss = 0.00620247\n",
            "Iteration 589, loss = 0.00610757\n",
            "Iteration 590, loss = 0.00611913\n",
            "Iteration 591, loss = 0.00607792\n",
            "Iteration 592, loss = 0.00606942\n",
            "Iteration 593, loss = 0.00608722\n",
            "Iteration 594, loss = 0.00610543\n",
            "Iteration 595, loss = 0.00608682\n",
            "Iteration 596, loss = 0.00599194\n",
            "Iteration 597, loss = 0.00602557\n",
            "Iteration 598, loss = 0.00593741\n",
            "Iteration 599, loss = 0.00590722\n",
            "Iteration 600, loss = 0.00592315\n",
            "Iteration 601, loss = 0.00588463\n",
            "Iteration 602, loss = 0.00584850\n",
            "Iteration 603, loss = 0.00591636\n",
            "Iteration 604, loss = 0.00587431\n",
            "Iteration 605, loss = 0.00582381\n",
            "Iteration 606, loss = 0.00579684\n",
            "Iteration 607, loss = 0.00581468\n",
            "Iteration 608, loss = 0.00575840\n",
            "Iteration 609, loss = 0.00585396\n",
            "Iteration 610, loss = 0.00574126\n",
            "Iteration 611, loss = 0.00575622\n",
            "Iteration 612, loss = 0.00571338\n",
            "Iteration 613, loss = 0.00568822\n",
            "Iteration 614, loss = 0.00572666\n",
            "Iteration 615, loss = 0.00575707\n",
            "Iteration 616, loss = 0.00565199\n",
            "Iteration 617, loss = 0.00568426\n",
            "Iteration 618, loss = 0.00561590\n",
            "Iteration 619, loss = 0.00564307\n",
            "Iteration 620, loss = 0.00560778\n",
            "Iteration 621, loss = 0.00556414\n",
            "Iteration 622, loss = 0.00561820\n",
            "Iteration 623, loss = 0.00553836\n",
            "Iteration 624, loss = 0.00556052\n",
            "Iteration 625, loss = 0.00552463\n",
            "Iteration 626, loss = 0.00551706\n",
            "Iteration 627, loss = 0.00547350\n",
            "Iteration 628, loss = 0.00547590\n",
            "Iteration 629, loss = 0.00551022\n",
            "Iteration 630, loss = 0.00558334\n",
            "Iteration 631, loss = 0.00545666\n",
            "Iteration 632, loss = 0.00538193\n",
            "Iteration 633, loss = 0.00538873\n",
            "Iteration 634, loss = 0.00542317\n",
            "Iteration 635, loss = 0.00537922\n",
            "Iteration 636, loss = 0.00536478\n",
            "Iteration 637, loss = 0.00535224\n",
            "Iteration 638, loss = 0.00534620\n",
            "Iteration 639, loss = 0.00531827\n",
            "Iteration 640, loss = 0.00532497\n",
            "Iteration 641, loss = 0.00528162\n",
            "Iteration 642, loss = 0.00529160\n",
            "Iteration 643, loss = 0.00524654\n",
            "Iteration 644, loss = 0.00518762\n",
            "Iteration 645, loss = 0.00532091\n",
            "Iteration 646, loss = 0.00522554\n",
            "Iteration 647, loss = 0.00522665\n",
            "Iteration 648, loss = 0.00520834\n",
            "Iteration 649, loss = 0.00512886\n",
            "Iteration 650, loss = 0.00515424\n",
            "Iteration 651, loss = 0.00513361\n",
            "Iteration 652, loss = 0.00518463\n",
            "Iteration 653, loss = 0.00513506\n",
            "Iteration 654, loss = 0.00510138\n",
            "Iteration 655, loss = 0.00508258\n",
            "Iteration 656, loss = 0.00504249\n",
            "Iteration 657, loss = 0.00508127\n",
            "Iteration 658, loss = 0.00512725\n",
            "Iteration 659, loss = 0.00513427\n",
            "Iteration 660, loss = 0.00502924\n",
            "Iteration 661, loss = 0.00500307\n",
            "Iteration 662, loss = 0.00502827\n",
            "Iteration 663, loss = 0.00499575\n",
            "Iteration 664, loss = 0.00495145\n",
            "Iteration 665, loss = 0.00497270\n",
            "Iteration 666, loss = 0.00493095\n",
            "Iteration 667, loss = 0.00489983\n",
            "Iteration 668, loss = 0.00491646\n",
            "Iteration 669, loss = 0.00495873\n",
            "Iteration 670, loss = 0.00491498\n",
            "Iteration 671, loss = 0.00492388\n",
            "Iteration 672, loss = 0.00490360\n",
            "Iteration 673, loss = 0.00482852\n",
            "Iteration 674, loss = 0.00477833\n",
            "Iteration 675, loss = 0.00484217\n",
            "Iteration 676, loss = 0.00484657\n",
            "Iteration 677, loss = 0.00484267\n",
            "Iteration 678, loss = 0.00480268\n",
            "Iteration 679, loss = 0.00473455\n",
            "Iteration 680, loss = 0.00474224\n",
            "Iteration 681, loss = 0.00478536\n",
            "Iteration 682, loss = 0.00475729\n",
            "Iteration 683, loss = 0.00468956\n",
            "Iteration 684, loss = 0.00466433\n",
            "Iteration 685, loss = 0.00471332\n",
            "Iteration 686, loss = 0.00473979\n",
            "Iteration 687, loss = 0.00467377\n",
            "Iteration 688, loss = 0.00461909\n",
            "Iteration 689, loss = 0.00472368\n",
            "Iteration 690, loss = 0.00458732\n",
            "Iteration 691, loss = 0.00468664\n",
            "Iteration 692, loss = 0.00470223\n",
            "Iteration 693, loss = 0.00457807\n",
            "Iteration 694, loss = 0.00459517\n",
            "Iteration 695, loss = 0.00456620\n",
            "Iteration 696, loss = 0.00454146\n",
            "Iteration 697, loss = 0.00451613\n",
            "Iteration 698, loss = 0.00451361\n",
            "Iteration 699, loss = 0.00450315\n",
            "Iteration 700, loss = 0.00451247\n",
            "Iteration 701, loss = 0.00453304\n",
            "Iteration 702, loss = 0.00451580\n",
            "Iteration 703, loss = 0.00448173\n",
            "Iteration 704, loss = 0.00452210\n",
            "Iteration 705, loss = 0.00442443\n",
            "Iteration 706, loss = 0.00444422\n",
            "Iteration 707, loss = 0.00440066\n",
            "Iteration 708, loss = 0.00441448\n",
            "Iteration 709, loss = 0.00449513\n",
            "Iteration 710, loss = 0.00448222\n",
            "Iteration 711, loss = 0.00437460\n",
            "Iteration 712, loss = 0.00435586\n",
            "Iteration 713, loss = 0.00447668\n",
            "Iteration 714, loss = 0.00443356\n",
            "Iteration 715, loss = 0.00442469\n",
            "Iteration 716, loss = 0.00436817\n",
            "Iteration 717, loss = 0.00431287\n",
            "Iteration 718, loss = 0.00434243\n",
            "Iteration 719, loss = 0.00432051\n",
            "Iteration 720, loss = 0.00426155\n",
            "Iteration 721, loss = 0.00424637\n",
            "Iteration 722, loss = 0.00421217\n",
            "Iteration 723, loss = 0.00419790\n",
            "Iteration 724, loss = 0.00439497\n",
            "Iteration 725, loss = 0.00424103\n",
            "Iteration 726, loss = 0.00424692\n",
            "Iteration 727, loss = 0.00421404\n",
            "Iteration 728, loss = 0.00416106\n",
            "Iteration 729, loss = 0.00422017\n",
            "Iteration 730, loss = 0.00418245\n",
            "Iteration 731, loss = 0.00422487\n",
            "Iteration 732, loss = 0.00420205\n",
            "Iteration 733, loss = 0.00415761\n",
            "Iteration 734, loss = 0.00411454\n",
            "Iteration 735, loss = 0.00407167\n",
            "Iteration 736, loss = 0.00410866\n",
            "Iteration 737, loss = 0.00412069\n",
            "Iteration 738, loss = 0.00408117\n",
            "Iteration 739, loss = 0.00411783\n",
            "Iteration 740, loss = 0.00406381\n",
            "Iteration 741, loss = 0.00403729\n",
            "Iteration 742, loss = 0.00403175\n",
            "Iteration 743, loss = 0.00401979\n",
            "Iteration 744, loss = 0.00399730\n",
            "Iteration 745, loss = 0.00402611\n",
            "Iteration 746, loss = 0.00406037\n",
            "Iteration 747, loss = 0.00399973\n",
            "Iteration 748, loss = 0.00398057\n",
            "Iteration 749, loss = 0.00399914\n",
            "Iteration 750, loss = 0.00394460\n",
            "Iteration 751, loss = 0.00390851\n",
            "Iteration 752, loss = 0.00394723\n",
            "Iteration 753, loss = 0.00393282\n",
            "Iteration 754, loss = 0.00388128\n",
            "Iteration 755, loss = 0.00390162\n",
            "Iteration 756, loss = 0.00389102\n",
            "Iteration 757, loss = 0.00398408\n",
            "Iteration 758, loss = 0.00389380\n",
            "Iteration 759, loss = 0.00386820\n",
            "Iteration 760, loss = 0.00387860\n",
            "Iteration 761, loss = 0.00390097\n",
            "Iteration 762, loss = 0.00384659\n",
            "Iteration 763, loss = 0.00381801\n",
            "Iteration 764, loss = 0.00383430\n",
            "Iteration 765, loss = 0.00380271\n",
            "Iteration 766, loss = 0.00377548\n",
            "Iteration 767, loss = 0.00376799\n",
            "Iteration 768, loss = 0.00380677\n",
            "Iteration 769, loss = 0.00384997\n",
            "Iteration 770, loss = 0.00375693\n",
            "Iteration 771, loss = 0.00374348\n",
            "Iteration 772, loss = 0.00376585\n",
            "Iteration 773, loss = 0.00370899\n",
            "Iteration 774, loss = 0.00380408\n",
            "Iteration 775, loss = 0.00372798\n",
            "Iteration 776, loss = 0.00368741\n",
            "Iteration 777, loss = 0.00368710\n",
            "Iteration 778, loss = 0.00366050\n",
            "Iteration 779, loss = 0.00371289\n",
            "Iteration 780, loss = 0.00366033\n",
            "Iteration 781, loss = 0.00369386\n",
            "Iteration 782, loss = 0.00363558\n",
            "Iteration 783, loss = 0.00365411\n",
            "Iteration 784, loss = 0.00359321\n",
            "Iteration 785, loss = 0.00359449\n",
            "Iteration 786, loss = 0.00360753\n",
            "Iteration 787, loss = 0.00363767\n",
            "Iteration 788, loss = 0.00360542\n",
            "Iteration 789, loss = 0.00357868\n",
            "Iteration 790, loss = 0.00368585\n",
            "Iteration 791, loss = 0.00354829\n",
            "Iteration 792, loss = 0.00361274\n",
            "Iteration 793, loss = 0.00358471\n",
            "Iteration 794, loss = 0.00363912\n",
            "Iteration 795, loss = 0.00356058\n",
            "Iteration 796, loss = 0.00357873\n",
            "Iteration 797, loss = 0.00352964\n",
            "Iteration 798, loss = 0.00346549\n",
            "Iteration 799, loss = 0.00347128\n",
            "Iteration 800, loss = 0.00346128\n",
            "Iteration 801, loss = 0.00343462\n",
            "Iteration 802, loss = 0.00347146\n",
            "Iteration 803, loss = 0.00344040\n",
            "Iteration 804, loss = 0.00350378\n",
            "Iteration 805, loss = 0.00344671\n",
            "Iteration 806, loss = 0.00350117\n",
            "Iteration 807, loss = 0.00337852\n",
            "Iteration 808, loss = 0.00350194\n",
            "Iteration 809, loss = 0.00349206\n",
            "Iteration 810, loss = 0.00341166\n",
            "Iteration 811, loss = 0.00338829\n",
            "Iteration 812, loss = 0.00338787\n",
            "Iteration 813, loss = 0.00335239\n",
            "Iteration 814, loss = 0.00334485\n",
            "Iteration 815, loss = 0.00332398\n",
            "Iteration 816, loss = 0.00335199\n",
            "Iteration 817, loss = 0.00332812\n",
            "Iteration 818, loss = 0.00331739\n",
            "Iteration 819, loss = 0.00335434\n",
            "Iteration 820, loss = 0.00330551\n",
            "Iteration 821, loss = 0.00329901\n",
            "Iteration 822, loss = 0.00329982\n",
            "Iteration 823, loss = 0.00328844\n",
            "Iteration 824, loss = 0.00329602\n",
            "Iteration 825, loss = 0.00325921\n",
            "Iteration 826, loss = 0.00331046\n",
            "Iteration 827, loss = 0.00324664\n",
            "Iteration 828, loss = 0.00324730\n",
            "Iteration 829, loss = 0.00322310\n",
            "Iteration 830, loss = 0.00323964\n",
            "Iteration 831, loss = 0.00321759\n",
            "Iteration 832, loss = 0.00319925\n",
            "Iteration 833, loss = 0.00321380\n",
            "Iteration 834, loss = 0.00319699\n",
            "Iteration 835, loss = 0.00323567\n",
            "Iteration 836, loss = 0.00316201\n",
            "Iteration 837, loss = 0.00316624\n",
            "Iteration 838, loss = 0.00317113\n",
            "Iteration 839, loss = 0.00317548\n",
            "Iteration 840, loss = 0.00316432\n",
            "Iteration 841, loss = 0.00314124\n",
            "Iteration 842, loss = 0.00317449\n",
            "Iteration 843, loss = 0.00314718\n",
            "Iteration 844, loss = 0.00311424\n",
            "Iteration 845, loss = 0.00310407\n",
            "Iteration 846, loss = 0.00318580\n",
            "Iteration 847, loss = 0.00313727\n",
            "Iteration 848, loss = 0.00317778\n",
            "Iteration 849, loss = 0.00308253\n",
            "Iteration 850, loss = 0.00307460\n",
            "Iteration 851, loss = 0.00303873\n",
            "Iteration 852, loss = 0.00308894\n",
            "Iteration 853, loss = 0.00310406\n",
            "Iteration 854, loss = 0.00309397\n",
            "Iteration 855, loss = 0.00306388\n",
            "Iteration 856, loss = 0.00299719\n",
            "Iteration 857, loss = 0.00305021\n",
            "Iteration 858, loss = 0.00302109\n",
            "Iteration 859, loss = 0.00300493\n",
            "Iteration 860, loss = 0.00308964\n",
            "Iteration 861, loss = 0.00301443\n",
            "Iteration 862, loss = 0.00299403\n",
            "Iteration 863, loss = 0.00304925\n",
            "Iteration 864, loss = 0.00297066\n",
            "Iteration 865, loss = 0.00296703\n",
            "Iteration 866, loss = 0.00294954\n",
            "Iteration 867, loss = 0.00294383\n",
            "Iteration 868, loss = 0.00304412\n",
            "Iteration 869, loss = 0.00290500\n",
            "Iteration 870, loss = 0.00291884\n",
            "Iteration 871, loss = 0.00292164\n",
            "Iteration 872, loss = 0.00298129\n",
            "Iteration 873, loss = 0.00292019\n",
            "Iteration 874, loss = 0.00288841\n",
            "Iteration 875, loss = 0.00290882\n",
            "Iteration 876, loss = 0.00289166\n",
            "Iteration 877, loss = 0.00288554\n",
            "Iteration 878, loss = 0.00293693\n",
            "Iteration 879, loss = 0.00290694\n",
            "Iteration 880, loss = 0.00287131\n",
            "Iteration 881, loss = 0.00287165\n",
            "Iteration 882, loss = 0.00294612\n",
            "Iteration 883, loss = 0.00285506\n",
            "Iteration 884, loss = 0.00292018\n",
            "Iteration 885, loss = 0.00288274\n",
            "Iteration 886, loss = 0.00286183\n",
            "Iteration 887, loss = 0.00288909\n",
            "Iteration 888, loss = 0.00295089\n",
            "Iteration 889, loss = 0.00281258\n",
            "Iteration 890, loss = 0.00277538\n",
            "Iteration 891, loss = 0.00282789\n",
            "Iteration 892, loss = 0.00276649\n",
            "Iteration 893, loss = 0.00276304\n",
            "Iteration 894, loss = 0.00275578\n",
            "Iteration 895, loss = 0.00277728\n",
            "Iteration 896, loss = 0.00279901\n",
            "Iteration 897, loss = 0.00273758\n",
            "Iteration 898, loss = 0.00277218\n",
            "Iteration 899, loss = 0.00277700\n",
            "Iteration 900, loss = 0.00274455\n",
            "Iteration 901, loss = 0.00268582\n",
            "Iteration 902, loss = 0.00272920\n",
            "Iteration 903, loss = 0.00269323\n",
            "Iteration 904, loss = 0.00270755\n",
            "Iteration 905, loss = 0.00272404\n",
            "Iteration 906, loss = 0.00268344\n",
            "Iteration 907, loss = 0.00270232\n",
            "Iteration 908, loss = 0.00268675\n",
            "Iteration 909, loss = 0.00271076\n",
            "Iteration 910, loss = 0.00267155\n",
            "Iteration 911, loss = 0.00265659\n",
            "Iteration 912, loss = 0.00268748\n",
            "Iteration 913, loss = 0.00263397\n",
            "Iteration 914, loss = 0.00263446\n",
            "Iteration 915, loss = 0.00264871\n",
            "Iteration 916, loss = 0.00270007\n",
            "Iteration 917, loss = 0.00262282\n",
            "Iteration 918, loss = 0.00261063\n",
            "Iteration 919, loss = 0.00259087\n",
            "Iteration 920, loss = 0.00264244\n",
            "Iteration 921, loss = 0.00259227\n",
            "Iteration 922, loss = 0.00260329\n",
            "Iteration 923, loss = 0.00256568\n",
            "Iteration 924, loss = 0.00262900\n",
            "Iteration 925, loss = 0.00267078\n",
            "Iteration 926, loss = 0.00256298\n",
            "Iteration 927, loss = 0.00258367\n",
            "Iteration 928, loss = 0.00257262\n",
            "Iteration 929, loss = 0.00257760\n",
            "Iteration 930, loss = 0.00257298\n",
            "Iteration 931, loss = 0.00255260\n",
            "Iteration 932, loss = 0.00250873\n",
            "Iteration 933, loss = 0.00253145\n",
            "Iteration 934, loss = 0.00253303\n",
            "Iteration 935, loss = 0.00250403\n",
            "Iteration 936, loss = 0.00251209\n",
            "Iteration 937, loss = 0.00257969\n",
            "Iteration 938, loss = 0.00247527\n",
            "Iteration 939, loss = 0.00251760\n",
            "Iteration 940, loss = 0.00252938\n",
            "Iteration 941, loss = 0.00253558\n",
            "Iteration 942, loss = 0.00245292\n",
            "Iteration 943, loss = 0.00248340\n",
            "Iteration 944, loss = 0.00247141\n",
            "Iteration 945, loss = 0.00245496\n",
            "Iteration 946, loss = 0.00247452\n",
            "Iteration 947, loss = 0.00251964\n",
            "Iteration 948, loss = 0.00243994\n",
            "Iteration 949, loss = 0.00248443\n",
            "Iteration 950, loss = 0.00242781\n",
            "Iteration 951, loss = 0.00245235\n",
            "Iteration 952, loss = 0.00245400\n",
            "Iteration 953, loss = 0.00243841\n",
            "Iteration 954, loss = 0.00241826\n",
            "Iteration 955, loss = 0.00241729\n",
            "Iteration 956, loss = 0.00240154\n",
            "Iteration 957, loss = 0.00242587\n",
            "Iteration 958, loss = 0.00240210\n",
            "Iteration 959, loss = 0.00235956\n",
            "Iteration 960, loss = 0.00236484\n",
            "Iteration 961, loss = 0.00236009\n",
            "Iteration 962, loss = 0.00240421\n",
            "Iteration 963, loss = 0.00233427\n",
            "Iteration 964, loss = 0.00240518\n",
            "Iteration 965, loss = 0.00240593\n",
            "Iteration 966, loss = 0.00230781\n",
            "Iteration 967, loss = 0.00243409\n",
            "Iteration 968, loss = 0.00233772\n",
            "Iteration 969, loss = 0.00232587\n",
            "Iteration 970, loss = 0.00234825\n",
            "Iteration 971, loss = 0.00231309\n",
            "Iteration 972, loss = 0.00228838\n",
            "Iteration 973, loss = 0.00231731\n",
            "Iteration 974, loss = 0.00227216\n",
            "Iteration 975, loss = 0.00226429\n",
            "Iteration 976, loss = 0.00228962\n",
            "Iteration 977, loss = 0.00228124\n",
            "Iteration 978, loss = 0.00227383\n",
            "Iteration 979, loss = 0.00230357\n",
            "Iteration 980, loss = 0.00226324\n",
            "Iteration 981, loss = 0.00226731\n",
            "Iteration 982, loss = 0.00229569\n",
            "Iteration 983, loss = 0.00223848\n",
            "Iteration 984, loss = 0.00226966\n",
            "Iteration 985, loss = 0.00227393\n",
            "Iteration 986, loss = 0.00225391\n",
            "Iteration 987, loss = 0.00217996\n",
            "Iteration 988, loss = 0.00223305\n",
            "Iteration 989, loss = 0.00223755\n",
            "Iteration 990, loss = 0.00223169\n",
            "Iteration 991, loss = 0.00220894\n",
            "Iteration 992, loss = 0.00219045\n",
            "Iteration 993, loss = 0.00220310\n",
            "Iteration 994, loss = 0.00218009\n",
            "Iteration 995, loss = 0.00218308\n",
            "Iteration 996, loss = 0.00223777\n",
            "Iteration 997, loss = 0.00216956\n",
            "Iteration 998, loss = 0.00222916\n",
            "Iteration 999, loss = 0.00218093\n",
            "Iteration 1000, loss = 0.00218662\n",
            "Iteration 1001, loss = 0.00217671\n",
            "Iteration 1002, loss = 0.00213574\n",
            "Iteration 1003, loss = 0.00219430\n",
            "Iteration 1004, loss = 0.00216277\n",
            "Iteration 1005, loss = 0.00215193\n",
            "Iteration 1006, loss = 0.00215890\n",
            "Iteration 1007, loss = 0.00212100\n",
            "Iteration 1008, loss = 0.00217210\n",
            "Iteration 1009, loss = 0.00217263\n",
            "Iteration 1010, loss = 0.00209176\n",
            "Iteration 1011, loss = 0.00211299\n",
            "Iteration 1012, loss = 0.00210413\n",
            "Iteration 1013, loss = 0.00214773\n",
            "Iteration 1014, loss = 0.00211492\n",
            "Iteration 1015, loss = 0.00210760\n",
            "Iteration 1016, loss = 0.00211387\n",
            "Iteration 1017, loss = 0.00218035\n",
            "Iteration 1018, loss = 0.00211976\n",
            "Iteration 1019, loss = 0.00210843\n",
            "Iteration 1020, loss = 0.00205951\n",
            "Iteration 1021, loss = 0.00203730\n",
            "Iteration 1022, loss = 0.00205692\n",
            "Iteration 1023, loss = 0.00208991\n",
            "Iteration 1024, loss = 0.00213495\n",
            "Iteration 1025, loss = 0.00212858\n",
            "Iteration 1026, loss = 0.00202259\n",
            "Iteration 1027, loss = 0.00212126\n",
            "Iteration 1028, loss = 0.00208835\n",
            "Iteration 1029, loss = 0.00202515\n",
            "Iteration 1030, loss = 0.00206400\n",
            "Iteration 1031, loss = 0.00202368\n",
            "Iteration 1032, loss = 0.00200314\n",
            "Iteration 1033, loss = 0.00205749\n",
            "Iteration 1034, loss = 0.00203660\n",
            "Iteration 1035, loss = 0.00201661\n",
            "Iteration 1036, loss = 0.00202508\n",
            "Iteration 1037, loss = 0.00198742\n",
            "Iteration 1038, loss = 0.00197116\n",
            "Iteration 1039, loss = 0.00202635\n",
            "Iteration 1040, loss = 0.00204963\n",
            "Iteration 1041, loss = 0.00198823\n",
            "Iteration 1042, loss = 0.00204237\n",
            "Iteration 1043, loss = 0.00198314\n",
            "Iteration 1044, loss = 0.00197996\n",
            "Iteration 1045, loss = 0.00198293\n",
            "Iteration 1046, loss = 0.00200263\n",
            "Iteration 1047, loss = 0.00199939\n",
            "Iteration 1048, loss = 0.00192064\n",
            "Iteration 1049, loss = 0.00191594\n",
            "Iteration 1050, loss = 0.00195592\n",
            "Iteration 1051, loss = 0.00192112\n",
            "Iteration 1052, loss = 0.00190179\n",
            "Iteration 1053, loss = 0.00191155\n",
            "Iteration 1054, loss = 0.00191101\n",
            "Iteration 1055, loss = 0.00192532\n",
            "Iteration 1056, loss = 0.00189976\n",
            "Iteration 1057, loss = 0.00190533\n",
            "Iteration 1058, loss = 0.00190016\n",
            "Iteration 1059, loss = 0.00191474\n",
            "Iteration 1060, loss = 0.00190438\n",
            "Iteration 1061, loss = 0.00191815\n",
            "Iteration 1062, loss = 0.00191157\n",
            "Iteration 1063, loss = 0.00189191\n",
            "Training loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(hidden_layer_sizes=(10, 10), max_iter=1500, tol=1e-05,\n",
              "              verbose=True)"
            ],
            "text/html": [
              "<style>#sk-container-id-8 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-8 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-8 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-8 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-8 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-8 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-8 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-8 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-8 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-8 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-8 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-8 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-8 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-8 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-8 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-8 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-8 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-8 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-8 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-8 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-8 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-8 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-8 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-8 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-8 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-8 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-8 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-8 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-8 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-8 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-8 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-8 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-8 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-8 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-8 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-8 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-8 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(10, 10), max_iter=1500, tol=1e-05,\n",
              "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MLPClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.neural_network.MLPClassifier.html\">?<span>Documentation for MLPClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>MLPClassifier(hidden_layer_sizes=(10, 10), max_iter=1500, tol=1e-05,\n",
              "              verbose=True)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "previsao_credit = rede_neural_credit.predict(X_credit_teste)\n",
        "accuracy_score(y_credit_teste, previsao_credit)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpi91h0khBFB",
        "outputId": "49962a2b-b0ed-440f-a84e-1b717a4f64d4"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.998"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm = ConfusionMatrix(rede_neural_credit)\n",
        "cm.fit(X_credit_treinamento, y_credit_treinamento)\n",
        "cm.score(X_credit_teste, y_credit_teste)\n",
        "cm.poof()\n",
        "#"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "id": "U_m_L0_NhLkg",
        "outputId": "5b1849f0-1001-472a-a82c-837cb35c79e4"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x550 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: title={'center': 'MLPClassifier Confusion Matrix'}, xlabel='Predicted Class', ylabel='True Class'>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_credit_teste, previsao_credit))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8b4S2YChdMx",
        "outputId": "44ea1c9a-1fcc-4637-fdc1-c5d1559bd2be"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       436\n",
            "           1       0.98      1.00      0.99        64\n",
            "\n",
            "    accuracy                           1.00       500\n",
            "   macro avg       0.99      1.00      1.00       500\n",
            "weighted avg       1.00      1.00      1.00       500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(caminho + 'census.pkl', 'rb') as f:\n",
        "  X_census_treinamento, y_census_treinamento, X_census_teste, y_census_teste = pickle.load(f)\n"
      ],
      "metadata": {
        "id": "5qdeR3TQigog"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rede_neural_census = MLPClassifier(verbose = True,\n",
        "                                   max_iter = 1000,\n",
        "                                   tol=0.0000100,\n",
        "                                   hidden_layer_sizes=(70, 70))\n",
        "rede_neural_census.fit(X_census_treinamento, y_census_treinamento)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "MOFYwmyoinwX",
        "outputId": "df8afff7-543e-4232-892c-d33a0bf7ecfd"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 11.49605143\n",
            "Iteration 2, loss = 11.22105433\n",
            "Iteration 3, loss = 10.73027074\n",
            "Iteration 4, loss = 11.27479723\n",
            "Iteration 5, loss = 11.22528709\n",
            "Iteration 6, loss = 10.70077246\n",
            "Iteration 7, loss = 11.26054667\n",
            "Iteration 8, loss = 10.30935289\n",
            "Iteration 9, loss = 11.26363430\n",
            "Iteration 10, loss = 11.23411886\n",
            "Iteration 11, loss = 10.55026129\n",
            "Iteration 12, loss = 10.84032820\n",
            "Iteration 13, loss = 10.91534158\n",
            "Iteration 14, loss = 11.00644335\n",
            "Iteration 15, loss = 10.56466476\n",
            "Iteration 16, loss = 10.92208912\n",
            "Iteration 17, loss = 10.44093510\n",
            "Iteration 18, loss = 10.31478475\n",
            "Iteration 19, loss = 11.30214155\n",
            "Training loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(hidden_layer_sizes=(70, 70), max_iter=1000, tol=1e-05,\n",
              "              verbose=True)"
            ],
            "text/html": [
              "<style>#sk-container-id-12 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-12 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-12 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-12 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-12 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-12 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-12 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-12 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-12 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-12 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-12 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-12 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-12 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-12 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-12 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-12 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-12 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-12 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-12 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-12 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(70, 70), max_iter=1000, tol=1e-05,\n",
              "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MLPClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.neural_network.MLPClassifier.html\">?<span>Documentation for MLPClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>MLPClassifier(hidden_layer_sizes=(70, 70), max_iter=1000, tol=1e-05,\n",
              "              verbose=True)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "previsao_census = rede_neural_census.predict(X_census_teste)\n",
        "accuracy_score(y_census_teste, previsao_census)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpKqH1i1ji0l",
        "outputId": "b7be9643-7367-44b1-97f0-076420fac0d1"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7875019192384461"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm = ConfusionMatrix(rede_neural_census)\n",
        "cm.fit(X_census_treinamento, y_census_treinamento)\n",
        "cm.score(X_census_teste, y_census_teste)\n",
        "cm.poof()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "id": "0w9eet0EjpkR",
        "outputId": "55bf90be-ed64-4510-977b-49982f68847a"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x550 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: title={'center': 'MLPClassifier Confusion Matrix'}, xlabel='Predicted Class', ylabel='True Class'>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    }
  ]
}